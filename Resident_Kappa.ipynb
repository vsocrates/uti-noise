{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "import numpy as np\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "from nltk.metrics.agreement import AnnotationTask\n",
    "from nltk.metrics.distance import masi_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token-based (NER/Span) - Two annotators (F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prodigy_kappa import compute_prodigy_ner_F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_f = \"/home/vs428/project/UTI_Noise_data/UTI_symptoms_GOLD_Adj_resident_train.jsonl\"\n",
    "perkins_f = \"/home/vs428/project/UTI_Noise_data/UTI_symptoms_RESIDENT_KAPPA-perkins.jsonl\"\n",
    "# kearns_f = \"/home/vs428/project/UTI_Noise_data/UTI_symptoms_RESIDENT_KAPPA-kearns.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_anns = []\n",
    "with jsonlines.open(gold_f) as f:\n",
    "    for x in f:\n",
    "        gold_anns.append(x)\n",
    "        \n",
    "cmp_anns = []\n",
    "with jsonlines.open(perkins_f) as f:\n",
    "    for x in f:\n",
    "        cmp_anns.append(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\"Dysuria\",  \"Hematuria\", \"Urinary_frequency\", \"Urinary_urgency\", \"Urinary_incontinence\", \"Urinary_retention\", \"Abdominal_pain\", \"Flank_pain\", \"Back_pain\", \"Low_back_pain\", \"Pelvic_pain\", \"Fever\", \"Fatigue\", \"Altered_mental_status\", \"Suprapubic_tenderness\", \"CVA_tenderness\", \"Abdominal_tenderness\"]\n",
    "x = compute_prodigy_ner_F1(labels, gold_f, perkins_f)\n",
    "y, supports = compute_prodigy_ner_F1(labels, gold_f, perkins_f, overlap=\"type\", weighted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "supports['Urinary_incontinence'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {label:support/sum(supports.values()) if support != 0 else 0 for label, support in supports.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abdominal_pain': 0.3978494623655914,\n",
       " 'Abdominal_tenderness': 0.051075268817204304,\n",
       " 'Suprapubic_tenderness': 0.026881720430107527,\n",
       " 'CVA_tenderness': 0.021505376344086023,\n",
       " 'Hematuria': 0.07258064516129033,\n",
       " 'Flank_pain': 0.1478494623655914,\n",
       " 'Urinary_retention': 0.01881720430107527,\n",
       " 'Low_back_pain': 0.04838709677419355,\n",
       " 'Dysuria': 0.06720430107526881,\n",
       " 'Fatigue': 0.016129032258064516,\n",
       " 'Altered_mental_status': 0.008064516129032258,\n",
       " 'Back_pain': 0.021505376344086023,\n",
       " 'Pelvic_pain': 0.03763440860215054,\n",
       " 'Urinary_frequency': 0.03225806451612903,\n",
       " 'Urinary_urgency': 0.008064516129032258,\n",
       " 'Fever': 0.024193548387096774,\n",
       " 'Urinary_incontinence': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights\n",
    "z = {}\n",
    "for label in labels:\n",
    "    if weights[label] != 0:\n",
    "        z[label] = y[label] * weights[label]\n",
    "    else:\n",
    "        z[label] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8214800598735046"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(z.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records([x, y, supports, z]).to_csv(\"perkins_before_after_overlap_kappa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check why Urinary_incontinence is 0.0\n",
    "\n",
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_spans = [ann['spans'] for ann in gold_anns]\n",
    "cmp_spans = [ann['spans'] for ann in cmp_anns if \"spans\" in ann.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_spans = [item for sublist in gold_spans for item in sublist]\n",
    "cmp_spans = [item for sublist in cmp_spans for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_spans_dysuria = [span for span in gold_spans if span['label'] == \"Urinary_incontinence\"]\n",
    "cmp_spans_dysuria = [span for span in cmp_spans if span['label'] == \"Urinary_incontinence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_spans_dysuria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp_spans_dysuria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for span in gold_spans_dysuria:\n",
    "    if \"source\" in span:\n",
    "        span.pop(\"source\")\n",
    "    if \"input_hash\" in span:\n",
    "        span.pop(\"input_hash\")\n",
    "    if \"text\" in span:\n",
    "        span.pop(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_spans_dysuria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we only have 5 values in our dictionary\n",
    "gold_spans = [ann['spans'] for ann in gold_anns if \"spans\" in ann.keys()]\n",
    "gold_spans = [item for sublist in gold_spans for item in sublist]\n",
    "\n",
    "anns_spans = [ann['spans'] for ann in cmp_anns if \"spans\" in ann.keys()]\n",
    "anns_spans = [item for sublist in anns_spans for item in sublist]\n",
    "\n",
    "spans = gold_spans + anns_spans\n",
    "\n",
    "span_keys = [list(span.keys()) for span in spans]\n",
    "span_keys = [item for sublist in span_keys for item in sublist]\n",
    "span_keys = set(span_keys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Text Classification By Label (Fleiss' Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns = []\n",
    "with jsonlines.open(\"/home/vs428/project/Incarceration_Data/incarceration_status_initial.jsonl\") as reader:\n",
    "    for ann in reader:\n",
    "        anns.append(ann)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', '_input_hash', '_task_hash', 'options', '_view_id', 'config', 'accept', 'answer', '_timestamp', '_annotator_id', '_session_id'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arrested', 'On_Probation']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns[0]['accept']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prodigy_fleissk_textcat(labels, *ann_files, overlap=\"full\"):\n",
    "    '''Takes in a list of labels and a set of prodigy jsonl annotation files \n",
    "       and computes the per-label Fleiss' Kappa. Fleiss' kappa is a generalization\n",
    "       of Scott's Pi (similar to Cohen's Kappa) for >2 annotators.\n",
    "       \n",
    "       We also assume that there are no missing ratings from any annotator. \n",
    "       If so, we drop the row. \n",
    "\n",
    "       Requires statsmodels\n",
    "    '''\n",
    "    # read in all annotation files    \n",
    "    anns = []            \n",
    "    for ann_file in ann_files:\n",
    "        with jsonlines.open(ann_file) as reader:\n",
    "            # f_anns = []\n",
    "            for ann in reader:\n",
    "                # f_anns.append(ann)\n",
    "\n",
    "                anns.append(ann)\n",
    "    \n",
    "    # combine all text by input hash into a dictionary\n",
    "    anns_by_input_hash = defaultdict(list)\n",
    "    for ann in anns:\n",
    "        anns_by_input_hash[ann['_input_hash']].append(ann)\n",
    "            \n",
    "    # compute per-label kappa\n",
    "    kappas = {}\n",
    "    N_DOCS = len(anns_by_input_hash.keys())\n",
    "    for label in labels:\n",
    "        # for each label, we just check if it exists or not\n",
    "        rater_mat = np.zeros(shape=(N_DOCS, 2))\n",
    "        for idx, (input_hash, anns) in enumerate(anns_by_input_hash.items()):\n",
    "            # skip if we don't have the same number of annotations as annotators\n",
    "            if len(anns) < len(ann_files):\n",
    "                continue\n",
    "\n",
    "            rater_mat[idx, 1] = sum([1 for ann in anns if label in ann['accept']])\n",
    "            rater_mat[idx, 0] = sum([1 for ann in anns if label not in ann['accept']])\n",
    "\n",
    "        # drop rows that have all 0s across\n",
    "        rater_mat[~np.all(rater_mat == 0, axis=1)]\n",
    "        kappas[label] = fleiss_kappa(rater_mat)\n",
    "        print(f\"Calculated kappa for {label}\")\n",
    "        \n",
    "    return kappas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "incar = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial.jsonl\"\n",
    "incar2 = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial_v2.jsonl\"\n",
    "incar3 = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial_v3.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [{\"id\":\"Prior_History_Incarceration\",\"text\":\"Prior_History_Incarceration\"},{\"id\":\"Current_Incarceration\",\"text\":\"Current_Incarceration\"},{\"id\":\"Recent_Incarceration\",\"text\":\"Recent_Incarceration\"},{\"id\":\"Family_History_Incarceration\",\"text\":\"Family_History_Incarceration\"},{\"id\":\"Arrested\",\"text\":\"Arrested\"},{\"id\":\"On_Probation\",\"text\":\"On_Probation\"},{\"id\":\"In_Police_Custody\",\"text\":\"In_Police_Custody\"},{\"id\":\"Brought_in_by_Police\",\"text\":\"Brought_in_by_Police\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [x['id'] for x in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated kappa for Prior_History_Incarceration\n",
      "Calculated kappa for Current_Incarceration\n",
      "Calculated kappa for Recent_Incarceration\n",
      "Calculated kappa for Family_History_Incarceration\n",
      "Calculated kappa for Arrested\n",
      "Calculated kappa for On_Probation\n",
      "Calculated kappa for In_Police_Custody\n",
      "Calculated kappa for Brought_in_by_Police\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# kappas = compute_prodigy_fleissk_textcat(labels, incar, incar2, incar3)\n",
    "kappas2 = compute_prodigy_fleissk_textcat(labels, incar, incar3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kappas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label Text Classification (Krippendorff's alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prodigy_KrippendorffA_textcat(labels, *ann_files, verbose=False):\n",
    "    '''Takes in a list of labels and a set of prodigy jsonl annotation files \n",
    "       and computes the overall Krippendorff's alpha. nltk's Krippendorff's alpha \n",
    "       handles multi-label multi-annotator settings and returns one score. \n",
    "       \n",
    "       We also assume that there are no missing ratings from any annotator. \n",
    "       If so, we drop the document. \n",
    "\n",
    "       Requires nltk\n",
    "    '''\n",
    "    # read in all annotation files    \n",
    "    anns = []            \n",
    "    for ann_file in ann_files:\n",
    "        with jsonlines.open(ann_file) as reader:\n",
    "            # f_anns = []\n",
    "            for ann in reader:\n",
    "                # f_anns.append(ann)\n",
    "\n",
    "                anns.append(ann)\n",
    "                \n",
    "    # combine all text by input hash into a dictionary\n",
    "    anns_by_input_hash = defaultdict(list)\n",
    "    for ann in anns:\n",
    "        anns_by_input_hash[ann['_input_hash']].append(ann)\n",
    "\n",
    "                \n",
    "    # nltk expects an AnnotationTask object which takes in a list of tuples\n",
    "    # of the form (coder, item, label)\n",
    "    task_anns = []\n",
    "    for input_hash, anns in anns_by_input_hash.items():\n",
    "        # make sure that at least one annotation has some label and all documents have all annotations\n",
    "        if len(anns) == len(ann_files) and all([False if not ann['accept'] else True for ann in anns]):\n",
    "            for ann in anns:\n",
    "                task_anns.append((ann['_annotator_id'], str(ann['_input_hash']), frozenset(ann['accept'])))\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(input_hash)\n",
    "\n",
    "    # generate nltk AnnotationTask and compute metrics\n",
    "    task = AnnotationTask(distance = masi_distance)\n",
    "    task.load_array(task_anns)\n",
    "    return task.alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "incar = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial.jsonl\"\n",
    "incar2 = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial_v2.jsonl\"\n",
    "incar3 = \"/home/vs428/project/Incarceration_Data/incarceration_status_initial_v3.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [{\"id\":\"Prior_History_Incarceration\",\"text\":\"Prior_History_Incarceration\"},{\"id\":\"Current_Incarceration\",\"text\":\"Current_Incarceration\"},{\"id\":\"Recent_Incarceration\",\"text\":\"Recent_Incarceration\"},{\"id\":\"Family_History_Incarceration\",\"text\":\"Family_History_Incarceration\"},{\"id\":\"Arrested\",\"text\":\"Arrested\"},{\"id\":\"On_Probation\",\"text\":\"On_Probation\"},{\"id\":\"In_Police_Custody\",\"text\":\"In_Police_Custody\"},{\"id\":\"Brought_in_by_Police\",\"text\":\"Brought_in_by_Police\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [x['id'] for x in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "krippendorffA = compute_prodigy_KrippendorffA_textcat(labels, incar, incar3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967416087311426"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krippendorffA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Review + NER.Manual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = []\n",
    "with jsonlines.open(\"/home/vs428/project/UTI_Noise_data/UTI_symptoms_GOLD_Adj_resident_train.jsonl\") as reader:\n",
    "    for line in reader:\n",
    "        gold.append(line)\n",
    "\n",
    "cmp = []        \n",
    "with jsonlines.open(\"/home/vs428/project/UTI_Noise_data/UTI_symptoms_RESIDENT_KAPPA-perkins.jsonl\") as reader:\n",
    "    for line in reader:\n",
    "        cmp.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold), len(cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gold[0]\n",
    "for ann in gold:\n",
    "    if \"versions\" in ann.keys():\n",
    "        ann.pop(\"versions\")\n",
    "    else:\n",
    "        print(ann)\n",
    "    ann['view_id'] = \"ner_manual\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with jsonlines.open(\"/home/vs428/project/UTI_Noise_data/UTI_symptoms_GOLD_Adj_resident_train_nermanual.jsonl\", \"w\") as writer:\n",
    "    writer.write_all(gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
